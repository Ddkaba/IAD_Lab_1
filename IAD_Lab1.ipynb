{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ddkaba/IAD_Lab_1/blob/main/IAD_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QeQeup-ME4S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import itertools\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwDq2UhwM3-F"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/Ddkaba/IAD_Lab_1/main/V2.csv\", index_col=0)\n",
        "if 'No' in dataset.columns:\n",
        "    dataset = dataset.drop(columns=['No'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLQOH-yRQLEf",
        "outputId": "f50d61aa-eabe-4496-bf33-12610eb0ae7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Общая информация\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 414 entries, 0 to 413\n",
            "Data columns (total 7 columns):\n",
            " #   Column                                  Non-Null Count  Dtype  \n",
            "---  ------                                  --------------  -----  \n",
            " 0   X1 transaction date                     414 non-null    float64\n",
            " 1   X2 house age                            205 non-null    float64\n",
            " 2   X3 distance to the nearest MRT station  414 non-null    float64\n",
            " 3   X4 number of convenience stores         414 non-null    int64  \n",
            " 4   X5 latitude                             414 non-null    float64\n",
            " 5   X6 longitude                            414 non-null    float64\n",
            " 6   Y house price of unit area              414 non-null    float64\n",
            "dtypes: float64(6), int64(1)\n",
            "memory usage: 25.9 KB\n",
            "None\n",
            "Количество записей (объектов): 414\n",
            "Количество признаков (фич): 7\n",
            "\n",
            "Названия столбцов:\n",
            "['X1 transaction date', 'X2 house age', 'X3 distance to the nearest MRT station', 'X4 number of convenience stores', 'X5 latitude', 'X6 longitude', 'Y house price of unit area']\n",
            "\n",
            "Типы данных:\n",
            "X1 transaction date                       float64\n",
            "X2 house age                              float64\n",
            "X3 distance to the nearest MRT station    float64\n",
            "X4 number of convenience stores             int64\n",
            "X5 latitude                               float64\n",
            "X6 longitude                              float64\n",
            "Y house price of unit area                float64\n",
            "dtype: object\n",
            "\n",
            "Пропущенные значения:\n",
            "X1 transaction date                         0\n",
            "X2 house age                              209\n",
            "X3 distance to the nearest MRT station      0\n",
            "X4 number of convenience stores             0\n",
            "X5 latitude                                 0\n",
            "X6 longitude                                0\n",
            "Y house price of unit area                  0\n",
            "dtype: int64\n",
            "Общее количество пропущенных значений: 209\n",
            "Целевая переменная\n",
            "\n",
            "Целевая переменная: Y house price of unit area\n",
            "Тип данных целевой переменной: float64\n",
            "Уникальные значения целевой переменной (первые 20): [37.9 42.2 47.3 54.8 43.1 32.1 40.3 46.7 18.8 22.1 41.4 58.1 39.3 23.8\n",
            " 34.3 50.5 70.1 37.4 42.3 47.7]\n",
            "Всего уникальных значений: 270\n",
            "Статистика\n",
            "       X1 transaction date  X2 house age  \\\n",
            "count           414.000000    205.000000   \n",
            "mean           2013.148971     18.206829   \n",
            "std               0.281967     11.747338   \n",
            "min            2012.667000      0.000000   \n",
            "25%            2012.917000      9.000000   \n",
            "50%            2013.167000     16.200000   \n",
            "75%            2013.417000     30.300000   \n",
            "max            2013.583000     43.800000   \n",
            "\n",
            "       X3 distance to the nearest MRT station  \\\n",
            "count                              414.000000   \n",
            "mean                              1083.885689   \n",
            "std                               1262.109595   \n",
            "min                                 23.382840   \n",
            "25%                                289.324800   \n",
            "50%                                492.231300   \n",
            "75%                               1454.279000   \n",
            "max                               6488.021000   \n",
            "\n",
            "       X4 number of convenience stores  X5 latitude  X6 longitude  \\\n",
            "count                       414.000000   414.000000    414.000000   \n",
            "mean                          4.094203    24.969030    121.533361   \n",
            "std                           2.945562     0.012410      0.015347   \n",
            "min                           0.000000    24.932070    121.473530   \n",
            "25%                           1.000000    24.963000    121.528085   \n",
            "50%                           4.000000    24.971100    121.538630   \n",
            "75%                           6.000000    24.977455    121.543305   \n",
            "max                          10.000000    25.014590    121.566270   \n",
            "\n",
            "       Y house price of unit area  \n",
            "count                  414.000000  \n",
            "mean                    37.980193  \n",
            "std                     13.606488  \n",
            "min                      7.600000  \n",
            "25%                     27.700000  \n",
            "50%                     38.450000  \n",
            "75%                     46.600000  \n",
            "max                    117.500000  \n",
            "Анализ кат. признаков\n",
            "\n",
            "Всего категориальных признаков: 0\n",
            "Корреляции с целевой переменной\n",
            "Y house price of unit area                1.000000\n",
            "X4 number of convenience stores           0.571005\n",
            "X5 latitude                               0.546307\n",
            "X6 longitude                              0.523287\n",
            "X1 transaction date                       0.087491\n",
            "X2 house age                             -0.195321\n",
            "X3 distance to the nearest MRT station   -0.673613\n",
            "Name: Y house price of unit area, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "print(\"Общая информация\")\n",
        "print(dataset.info())\n",
        "\n",
        "print(f\"Количество записей (объектов): {dataset.shape[0]}\")\n",
        "print(f\"Количество признаков (фич): {dataset.shape[1]}\")\n",
        "\n",
        "print(\"\\nНазвания столбцов:\")\n",
        "print(dataset.columns.tolist())\n",
        "\n",
        "print(\"\\nТипы данных:\")\n",
        "print(dataset.dtypes)\n",
        "\n",
        "print(\"\\nПропущенные значения:\")\n",
        "missing_values = dataset.isnull().sum()\n",
        "print(missing_values)\n",
        "print(f\"Общее количество пропущенных значений: {missing_values.sum()}\")\n",
        "\n",
        "print(\"Целевая переменная\")\n",
        "target_column = 'Y house price of unit area'\n",
        "if target_column in dataset.columns:\n",
        "    print(f\"\\nЦелевая переменная: {target_column}\")\n",
        "    print(f\"Тип данных целевой переменной: {dataset[target_column].dtype}\")\n",
        "    unique_values = dataset[target_column].unique()\n",
        "    print(f\"Уникальные значения целевой переменной (первые 20): {unique_values[:20]}\")\n",
        "    print(f\"Всего уникальных значений: {unique_values.size}\")\n",
        "    if dataset[target_column].nunique() <= 20:\n",
        "        print(\"Распределение классов:\")\n",
        "        print(dataset[target_column].value_counts())\n",
        "        print(\"Процентное соотношение классов:\")\n",
        "        print(dataset[target_column].value_counts(normalize=True) * 100)\n",
        "\n",
        "print(\"Статистика\")\n",
        "print(dataset.describe())\n",
        "\n",
        "print(\"Анализ кат. признаков\")\n",
        "categorical_features = []\n",
        "for col in dataset.columns:\n",
        "    unique_values = dataset[col].nunique(dropna=True)\n",
        "    if unique_values <= 10:\n",
        "        categorical_features.append(col)\n",
        "        print(f\"{col}: {unique_values} уникальных значений - {dataset[col].unique()}\")\n",
        "\n",
        "print(f\"\\nВсего категориальных признаков: {len(categorical_features)}\")\n",
        "\n",
        "print(\"Корреляционная матрица (тепловая карта)\")\n",
        "\n",
        "corr_matrix = dataset.corr(numeric_only=True)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Корреляционная матрица признаков')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Корреляции признаков с целевой переменной:\")\n",
        "if target_column in corr_matrix.columns:\n",
        "    print(corr_matrix[target_column].sort_values(ascending=False))\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg79CR6Q9x7k"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRSgYfZp9ge7"
      },
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Гистограммы по всем числовым признакам (без целевой)\n",
        "# Определим список числовых колонок и исключим целевую, если она есть\n",
        "feature_columns = dataset.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if 'Y house price of unit area' in feature_columns:\n",
        "    feature_columns.remove('Y house price of unit area')\n",
        "\n",
        "_ = dataset[feature_columns].hist(\n",
        "    bins=10,\n",
        "    figsize=(20, 15),\n",
        "    grid=False,\n",
        "    edgecolor='black'\n",
        ")\n",
        "plt.suptitle('Распределение числовых признаков', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LmVQK7B91BP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Bv9ZuPa9ge8"
      },
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Геовизуализация: долгота vs широта\n",
        "lon_col = 'X6 longitude'\n",
        "lat_col = 'X5 latitude'\n",
        "\n",
        "# Базовый scatter, как на слайде\n",
        "ax = dataset.plot(kind='scatter', x=lon_col, y=lat_col, alpha=0.1, figsize=(8, 6))\n",
        "ax.set_title('Расположение объектов (longitude vs latitude)')\n",
        "ax.set_xlabel('longitude')\n",
        "ax.set_ylabel('latitude')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Раскраска по целевой (если есть)\n",
        "if 'Y house price of unit area' in dataset.columns:\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    sc = plt.scatter(\n",
        "        dataset[lon_col], dataset[lat_col],\n",
        "        c=dataset['Y house price of unit area'], cmap='viridis',\n",
        "        s=25, alpha=0.6, edgecolors='none'\n",
        "    )\n",
        "    cbar = plt.colorbar(sc)\n",
        "    cbar.set_label('Y house price of unit area')\n",
        "    plt.title('Геоданные, окрашенные по целевой переменной')\n",
        "    plt.xlabel('longitude')\n",
        "    plt.ylabel('latitude')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzcnAAis91wh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-VRE4N19ge9"
      },
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Эксперименты с комбинациями атрибутов + пересчет корреляций\n",
        "TARGET = 'Y house price of unit area'\n",
        "\n",
        "dataset_fe = dataset.copy()\n",
        "\n",
        "df_original = dataset.copy()\n",
        "\n",
        "# 1) Взаимодействие возраста. Старый и далёкий объект «штрафуется» сильнее, новый рядом со станцией — «премируется». Это даёт модели не одну общую «цену километра», а разную в зависимости от возраста.\n",
        "age_med = dataset_fe['X2 house age'].median()\n",
        "age_filled_tmp = dataset_fe['X2 house age'].fillna(age_med)\n",
        "dataset_fe['age_x_mrt_distance'] = age_filled_tmp * dataset_fe['X3 distance to the nearest MRT station']\n",
        "\n",
        "df_engineered = dataset_fe.copy()\n",
        "\n",
        "# Корреляции\n",
        "corr = dataset_fe.corr(numeric_only=True)\n",
        "plt.figure(figsize=(13, 10))\n",
        "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
        "plt.title('Корреляции после инженерии признаков')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "if TARGET in corr.columns:\n",
        "    print('\\nТоп-15 корреляций с целевой:')\n",
        "    print(corr[TARGET].sort_values(ascending=False).head(15))\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpjriE_n92QC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbFeaa-d9ge-"
      },
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Импутация пропусков в X2 house age медианой + контроль результата\n",
        "\n",
        "df_original_preprocessed = dataset.copy()\n",
        "\n",
        "col = 'X2 house age'\n",
        "med = dataset_fe[col].median()\n",
        "missing_before = dataset_fe[col].isna().sum()\n",
        "\n",
        "dataset_fe[col] = dataset_fe[col].fillna(med)\n",
        "missing_after = dataset_fe[col].isna().sum()\n",
        "\n",
        "med2 = df_original_preprocessed[col].median()\n",
        "df_original_preprocessed[col] = df_original_preprocessed[col].fillna(med2)\n",
        "\n",
        "print(f\"Медиана {col}: {med:.3f}\")\n",
        "print(f\"Пропусков до/после: {missing_before} -> {missing_after}\")\n",
        "\n",
        "# Визуальная проверка распределения после импутации\n",
        "plt.figure(figsize=(6, 4))\n",
        "dataset_fe[col].hist(bins=20, edgecolor='black')\n",
        "plt.title(f'{col} после импутации медианой')\n",
        "plt.xlabel('age')\n",
        "plt.ylabel('count')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Корреляции\n",
        "corr = dataset_fe.corr(numeric_only=True)\n",
        "plt.figure(figsize=(13, 10))\n",
        "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
        "plt.title('Корреляции после инженерии признаков')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "if TARGET in corr.columns:\n",
        "    print('\\nТоп-15 корреляций с целевой:')\n",
        "    print(corr[TARGET].sort_values(ascending=False).head(15))\n",
        "# ### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZOQh8Cc92rP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsa5-Rae9ge_"
      },
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# SelectKBest (f_regression): оценка информативности признаков и выбор ТОП-5\n",
        "\n",
        "\n",
        "TARGET = 'Y house price of unit area'\n",
        "\n",
        "# Берём расширенный набор, если он уже посчитан; иначе — исходный\n",
        "source_df = dataset_fe if 'dataset_fe' in globals() else dataset\n",
        "\n",
        "# Числовые признаки\n",
        "X_num = source_df.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
        "y = source_df[TARGET]\n",
        "\n",
        "# Импутация оставшихся пропусков медианой (на всякий случай)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_num_imp = pd.DataFrame(imputer.fit_transform(X_num), columns=X_num.columns, index=X_num.index)\n",
        "\n",
        "# 1) Считаем баллы для всех фич\n",
        "all_selector = SelectKBest(score_func=f_regression, k='all')\n",
        "all_selector.fit(X_num_imp, y)\n",
        "\n",
        "scores_df = (\n",
        "    pd.DataFrame({'feature': X_num_imp.columns, 'score': all_selector.scores_})\n",
        "      .sort_values('score', ascending=False)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "print('Оценки информативности (f_regression), по убыванию:')\n",
        "print(scores_df)\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=scores_df, x='score', y='feature', color='#1f77b4')\n",
        "plt.title('SelectKBest: f_regression scores')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2) Выбор ТОП-K признаков\n",
        "K = 5\n",
        "selector = SelectKBest(score_func=f_regression, k=K)\n",
        "selector.fit(X_num_imp, y)\n",
        "selected_features = X_num_imp.columns[selector.get_support()].tolist()\n",
        "print(f'Топ-{K} признаков:')\n",
        "print(selected_features)\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VctayM8E93P3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BCzc-9-9gfA"
      },
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Удаление нерелевантных признаков, как на слайде\n",
        "cols_to_drop = ['X2 house age', 'X1 transaction date']\n",
        "\n",
        "# Работаем с расширенным набором, если он есть; иначе — с исходным\n",
        "df_ref = dataset_fe if 'dataset_fe' in globals() else dataset\n",
        "\n",
        "print('До:', df_ref.shape)\n",
        "df_ref.drop(columns=[c for c in cols_to_drop if c in df_ref.columns], axis=1, inplace=True)\n",
        "print('После:', df_ref.shape)\n",
        "print('Текущие столбцы:')\n",
        "print(df_ref.columns.tolist())\n",
        "\n",
        "# Если работали с исходным датасетом, синхронизируем переменную\n",
        "if 'dataset_fe' not in globals():\n",
        "    dataset = df_ref\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZDFbbvQ93un"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjZIJnUa9gfA"
      },
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Стандартизация числовых признаков (z = (x - mean) / std)\n",
        "TARGET = 'Y house price of unit area'\n",
        "\n",
        "# Базовый датафрейм для трансформации: используем расширенный, если есть\n",
        "base_df = dataset_fe if 'dataset_fe' in globals() else dataset\n",
        "\n",
        "# Отбираем числовые признаки, исключая целевую\n",
        "feature_cols = base_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if TARGET in feature_cols:\n",
        "    feature_cols.remove(TARGET)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled = scaler.fit_transform(base_df[feature_cols])\n",
        "standardized_df = pd.DataFrame(scaled, columns=feature_cols, index=base_df.index)\n",
        "\n",
        "# Сохраняем предобработанные варианты\n",
        "df_engineered_preprocessed = standardized_df.join(base_df[[TARGET]])\n",
        "\n",
        "print('Стандартизированы признаки:', feature_cols)\n",
        "print('Форма:', standardized_df.shape)\n",
        "print(standardized_df.head())\n",
        "\n",
        "# Быстрая проверка средних и СКО (должны быть ~0 и ~1)\n",
        "means = standardized_df.mean().round(4)\n",
        "stdevs = standardized_df.std(ddof=0).round(4)\n",
        "print('\\nСредние по столбцам (ожид. ≈ 0):')\n",
        "print(means)\n",
        "print('\\nСт. отклонения (ожид. ≈ 1):')\n",
        "print(stdevs)\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAR0quTN94Rw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7FEua6Z9gfB"
      },
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Train/Validation/Test split: 60% / 20% / 20%\n",
        "\n",
        "TARGET = 'Y house price of unit area'\n",
        "\n",
        "# Источник данных: используем расширенный набор, если он уже есть\n",
        "src = dataset_fe if 'dataset_fe' in globals() else dataset\n",
        "\n",
        "X = src.drop(columns=[TARGET])\n",
        "y = src[TARGET]\n",
        "\n",
        "# 1) Test split (20%)\n",
        "seed = 42\n",
        "test_size = 0.2\n",
        "val_size = 0.25  # 25% от train -> итог 60/20/20\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=seed\n",
        ")\n",
        "\n",
        "# 2) Validation split из обучающей части\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=val_size, random_state=seed\n",
        ")\n",
        "\n",
        "print('Shapes:')\n",
        "print('X_train:', X_train.shape, 'X_val:', X_val.shape, 'X_test:', X_test.shape)\n",
        "print('y_train:', y_train.shape, 'y_val:', y_val.shape, 'y_test:', y_test.shape)\n",
        "\n",
        "print('\\nX_train head:')\n",
        "print(X_train.head())\n",
        "print('\\nX_val head:')\n",
        "print(X_val.head())\n",
        "print('\\nX_test head:')\n",
        "print(X_test.head())\n",
        "\n",
        "print('\\ny_train head:')\n",
        "print(y_train.head())\n",
        "print('\\ny_val head:')\n",
        "print(y_val.head())\n",
        "print('\\ny_test head:')\n",
        "print(y_test.head())\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AmzhWaz94t4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox04fvjr9gfC"
      },
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Сравнение MLP и простой RNN на train/val для исходного и инженерного наборов\n",
        "keras = tf.keras\n",
        "\n",
        "np.random.seed(42)\n",
        "try:\n",
        "    tf.random.set_seed(42)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "TARGET = 'Y house price of unit area'\n",
        "\n",
        "# Проверим, что разбиение уже сделано (из предыдущей ячейки)\n",
        "assert 'X_train' in globals() and 'X_val' in globals(), 'Сначала запустите ячейку с train/val/test split.'\n",
        "train_idx = X_train.index\n",
        "val_idx = X_val.index\n",
        "\n",
        "# Подготовим словарь наборов\n",
        "datasets_map = {}\n",
        "datasets_map['original'] = dataset.copy()\n",
        "if 'dataset_fe' in globals():\n",
        "    datasets_map['engineered'] = dataset_fe.copy()\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, df in datasets_map.items():\n",
        "    # берем только числовые признаки\n",
        "    X_all = df.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
        "    y_all = df[TARGET]\n",
        "\n",
        "    # одинаковые индексы разбиения\n",
        "    X_tr = X_all.loc[train_idx]\n",
        "    y_tr = y_all.loc[train_idx]\n",
        "    X_va = X_all.loc[val_idx]\n",
        "    y_va = y_all.loc[val_idx]\n",
        "\n",
        "    # Импутация по train и стандартизация по train\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    X_tr_imp = imputer.fit_transform(X_tr)\n",
        "    X_va_imp = imputer.transform(X_va)\n",
        "\n",
        "    X_tr_std = scaler.fit_transform(X_tr_imp)\n",
        "    X_va_std = scaler.transform(X_va_imp)\n",
        "\n",
        "    input_dim = X_tr_std.shape[1]\n",
        "\n",
        "    # 1) Полносвязная регрессионная модель (MLP)\n",
        "    mlp = keras.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    mlp.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
        "    es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "    mlp.fit(X_tr_std, y_tr.values, validation_data=(X_va_std, y_va.values),\n",
        "            epochs=300, batch_size=32, verbose=0, callbacks=[es])\n",
        "\n",
        "    y_tr_pred = mlp.predict(X_tr_std, verbose=0).ravel()\n",
        "    y_va_pred = mlp.predict(X_va_std, verbose=0).ravel()\n",
        "    rmse_tr = float(np.sqrt(mean_squared_error(y_tr, y_tr_pred)))\n",
        "    r2_tr = float(r2_score(y_tr, y_tr_pred))\n",
        "    rmse_va = float(np.sqrt(mean_squared_error(y_va, y_va_pred)))\n",
        "    r2_va = float(r2_score(y_va, y_va_pred))\n",
        "    results.append({'dataset': name, 'model': 'MLP', 'rmse_train': rmse_tr, 'r2_train': r2_tr, 'rmse_val': rmse_va, 'r2_val': r2_va})\n",
        "\n",
        "    # 2) Простая рекуррентная сеть для регрессии (SimpleRNN)\n",
        "    # Представим признаки как одношаговую последовательность длиной input_dim\n",
        "    X_tr_seq = X_tr_std.reshape((-1, input_dim, 1))\n",
        "    X_va_seq = X_va_std.reshape((-1, input_dim, 1))\n",
        "\n",
        "    rnn = keras.Sequential([\n",
        "        layers.Input(shape=(input_dim, 1)),\n",
        "        layers.SimpleRNN(32, activation='tanh'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    rnn.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
        "    es2 = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "    rnn.fit(X_tr_seq, y_tr.values, validation_data=(X_va_seq, y_va.values),\n",
        "            epochs=300, batch_size=32, verbose=0, callbacks=[es2])\n",
        "\n",
        "    y_tr_pred = rnn.predict(X_tr_seq, verbose=0).ravel()\n",
        "    y_va_pred = rnn.predict(X_va_seq, verbose=0).ravel()\n",
        "    rmse_tr = float(np.sqrt(mean_squared_error(y_tr, y_tr_pred)))\n",
        "    r2_tr = float(r2_score(y_tr, y_tr_pred))\n",
        "    rmse_va = float(np.sqrt(mean_squared_error(y_va, y_va_pred)))\n",
        "    r2_va = float(r2_score(y_va, y_va_pred))\n",
        "    results.append({'dataset': name, 'model': 'SimpleRNN', 'rmse_train': rmse_tr, 'r2_train': r2_tr, 'rmse_val': rmse_va, 'r2_val': r2_va})\n",
        "\n",
        "# Сводная таблица\n",
        "res_df = pd.DataFrame(results)\n",
        "print(res_df.sort_values(['dataset', 'model']).to_string(index=False))\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUpsWRlF95xv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdlbXlI_9gfC"
      },
      "outputs": [],
      "source": [
        "print(\"Общая информация\")\n",
        "print(df_original.info())\n",
        "print(df_engineered_preprocessed.info())\n",
        "print(df_original_preprocessed.info())\n",
        "print(df_engineered.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Сравнение MLP и простой RNN на train/val для четырёх наборов:\n",
        "# df_original, df_engineered_preprocessed, df_original_preprocessed, df_engineered\n",
        "keras = tf.keras\n",
        "\n",
        "np.random.seed(42)\n",
        "try:\n",
        "    tf.random.set_seed(42)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "TARGET = 'Y house price of unit area'\n",
        "\n",
        "# Проверим, что разбиение уже сделано (из предыдущей ячейки)\n",
        "assert 'X_train' in globals() and 'X_val' in globals(), 'Сначала запустите ячейку с train/val/test split.'\n",
        "train_idx = X_train.index\n",
        "val_idx = X_val.index\n",
        "\n",
        "# Подготовим словарь наборов\n",
        "datasets_map = {}\n",
        "if 'df_original' in globals():\n",
        "    datasets_map['df_original'] = df_original.copy()\n",
        "if 'df_engineered_preprocessed' in globals():\n",
        "    datasets_map['df_engineered_preprocessed'] = df_engineered_preprocessed.copy()\n",
        "if 'df_original_preprocessed' in globals():\n",
        "    datasets_map['df_original_preprocessed'] = df_original_preprocessed.copy()\n",
        "if 'df_engineered' in globals():\n",
        "    datasets_map['df_engineered'] = df_engineered.copy()\n",
        "\n",
        "assert len(datasets_map) > 0, 'Нет доступных датафреймов из списка.'\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, df in datasets_map.items():\n",
        "    # Берем только числовые признаки\n",
        "    X_all = df.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
        "    y_all = df[TARGET]\n",
        "\n",
        "    # Одинаковые индексы разбиения\n",
        "    X_tr = X_all.loc[train_idx]\n",
        "    y_tr = y_all.loc[train_idx]\n",
        "    X_va = X_all.loc[val_idx]\n",
        "    y_va = y_all.loc[val_idx]\n",
        "\n",
        "    # Импутация по train и стандартизация по train\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    X_tr_imp = imputer.fit_transform(X_tr)\n",
        "    X_va_imp = imputer.transform(X_va)\n",
        "\n",
        "    X_tr_std = scaler.fit_transform(X_tr_imp)\n",
        "    X_va_std = scaler.transform(X_va_imp)\n",
        "\n",
        "    input_dim = X_tr_std.shape[1]\n",
        "\n",
        "    # 1) Полносвязная регрессионная модель (MLP)\n",
        "    mlp = keras.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    mlp.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
        "    es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "    mlp.fit(X_tr_std, y_tr.values, validation_data=(X_va_std, y_va.values),\n",
        "            epochs=300, batch_size=32, verbose=0, callbacks=[es])\n",
        "\n",
        "    y_tr_pred = mlp.predict(X_tr_std, verbose=0).ravel()\n",
        "    y_va_pred = mlp.predict(X_va_std, verbose=0).ravel()\n",
        "    rmse_tr = float(np.sqrt(mean_squared_error(y_tr, y_tr_pred)))\n",
        "    r2_tr = float(r2_score(y_tr, y_tr_pred))\n",
        "    rmse_va = float(np.sqrt(mean_squared_error(y_va, y_va_pred)))\n",
        "    r2_va = float(r2_score(y_va, y_va_pred))\n",
        "    results.append({'dataset': name, 'model': 'MLP', 'rmse_train': rmse_tr, 'r2_train': r2_tr, 'rmse_val': rmse_va, 'r2_val': r2_va})\n",
        "\n",
        "    # 2) Простая рекуррентная сеть для регрессии (SimpleRNN)\n",
        "    # Представим признаки как одношаговую последовательность длиной input_dim\n",
        "    X_tr_seq = X_tr_std.reshape((-1, input_dim, 1))\n",
        "    X_va_seq = X_va_std.reshape((-1, input_dim, 1))\n",
        "\n",
        "    rnn = keras.Sequential([\n",
        "        layers.Input(shape=(input_dim, 1)),\n",
        "        layers.SimpleRNN(32, activation='tanh'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    rnn.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
        "    es2 = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "    rnn.fit(X_tr_seq, y_tr.values, validation_data=(X_va_seq, y_va.values),\n",
        "            epochs=300, batch_size=32, verbose=0, callbacks=[es2])\n",
        "\n",
        "    y_tr_pred = rnn.predict(X_tr_seq, verbose=0).ravel()\n",
        "    y_va_pred = rnn.predict(X_va_seq, verbose=0).ravel()\n",
        "    rmse_tr = float(np.sqrt(mean_squared_error(y_tr, y_tr_pred)))\n",
        "    r2_tr = float(r2_score(y_tr, y_tr_pred))\n",
        "    rmse_va = float(np.sqrt(mean_squared_error(y_va, y_va_pred)))\n",
        "    r2_va = float(r2_score(y_va, y_va_pred))\n",
        "    results.append({'dataset': name, 'model': 'SimpleRNN', 'rmse_train': rmse_tr, 'r2_train': r2_tr, 'rmse_val': rmse_va, 'r2_val': r2_va})\n",
        "\n",
        "# Сводная таблица\n",
        "res_df = pd.DataFrame(results)\n",
        "print(res_df.sort_values(['dataset', 'model']).to_string(index=False))\n",
        "# ### END YOUR CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Оценка лучшей модели (MLP на df_original) на тестовом наборе\n",
        "keras = tf.keras\n",
        "\n",
        "# Проверяем, что сплит уже выполнен\n",
        "assert 'X_train' in globals() and 'X_val' in globals() and 'X_test' in globals(), 'Сначала запустите ячейку с train/val/test split.'\n",
        "\n",
        "TARGET = 'Y house price of unit area'\n",
        "\n",
        "# Лучший набор данных — исходный\n",
        "df = df_original.copy() if 'df_original' in globals() else dataset.copy()\n",
        "\n",
        "# Формируем обучающую выборку как train + val, тест — как есть\n",
        "trainval_idx = pd.Index(X_train.index).union(X_val.index)\n",
        "X_all = df.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
        "y_all = df[TARGET]\n",
        "\n",
        "X_trval = X_all.loc[trainval_idx]\n",
        "y_trval = y_all.loc[trainval_idx]\n",
        "X_te = X_all.loc[X_test.index]\n",
        "y_te = y_all.loc[X_test.index]\n",
        "\n",
        "# Импутация медианой и стандартизация по train+val\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_trval_imp = imputer.fit_transform(X_trval)\n",
        "X_te_imp = imputer.transform(X_te)\n",
        "\n",
        "X_trval_std = scaler.fit_transform(X_trval_imp)\n",
        "X_te_std = scaler.transform(X_te_imp)\n",
        "\n",
        "input_dim = X_trval_std.shape[1]\n",
        "\n",
        "# Архитектура и оптимизация, как в валидационном эксперименте\n",
        "mlp = keras.Sequential([\n",
        "    layers.Input(shape=(input_dim,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "mlp.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "# Тренируем на train+val с небольшим внутренним валидационным сплитом для ранней остановки\n",
        "mlp.fit(\n",
        "    X_trval_std, y_trval.values,\n",
        "    epochs=300, batch_size=32, verbose=0,\n",
        "    validation_split=0.1, callbacks=[es]\n",
        ")\n",
        "\n",
        "# Оценка на тесте\n",
        "y_test_pred = mlp.predict(X_te_std, verbose=0).ravel()\n",
        "rmse_test = float(np.sqrt(mean_squared_error(y_te, y_test_pred)))\n",
        "r2_test = float(r2_score(y_te, y_test_pred))\n",
        "\n",
        "print('Лучшая модель: MLP на df_original')\n",
        "print(f'Test RMSE: {rmse_test:.6f}')\n",
        "print(f'Test R^2: {r2_test:.6f}')\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Grid-поиск гиперпараметров для MLP на train/val для df_original\n",
        "\n",
        "keras = tf.keras\n",
        "np.random.seed(42)\n",
        "try:\n",
        "    tf.random.set_seed(42)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Гарантируем, что разбиение выполнено\n",
        "assert 'X_train' in globals() and 'X_val' in globals(), 'Сначала запустите ячейку с train/val/test split.'\n",
        "\n",
        "TARGET = 'Y house price of unit area'\n",
        "\n",
        "# Базовый датасет — исходный\n",
        "df = df_original.copy() if 'df_original' in globals() else dataset.copy()\n",
        "\n",
        "# Числовые признаки и целевая\n",
        "X_all = df.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
        "y_all = df[TARGET]\n",
        "\n",
        "# Выборки по уже готовым индексам\n",
        "train_idx = X_train.index\n",
        "val_idx = X_val.index\n",
        "X_tr = X_all.loc[train_idx]\n",
        "y_tr = y_all.loc[train_idx]\n",
        "X_va = X_all.loc[val_idx]\n",
        "y_va = y_all.loc[val_idx]\n",
        "\n",
        "# Преобразования: только fit на train, transform на val\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_tr_imp = imputer.fit_transform(X_tr)\n",
        "X_va_imp = imputer.transform(X_va)\n",
        "\n",
        "X_tr_std = scaler.fit_transform(X_tr_imp)\n",
        "X_va_std = scaler.transform(X_va_imp)\n",
        "\n",
        "input_dim = X_tr_std.shape[1]\n",
        "\n",
        "# Поиск по сетке\n",
        "param_grid = {\n",
        "    'hidden_units_list': [ (64, 32), (128, 64), (64, 32, 16) ],\n",
        "    'activation': ['relu'],\n",
        "    'learning_rate': [1e-3, 3e-4],\n",
        "    'batch_size': [16, 32],\n",
        "    'l2_value': [0.0, 1e-4],\n",
        "    'dropout_rate': [0.0, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "def build_mlp(input_dim: int,\n",
        "              hidden_units: tuple,\n",
        "              activation: str,\n",
        "              l2_value: float,\n",
        "              dropout_rate: float,\n",
        "              learning_rate: float):\n",
        "    layers_list = [layers.Input(shape=(input_dim,))]\n",
        "    kernel_reg = regularizers.l2(l2_value) if l2_value and l2_value > 0 else None\n",
        "    for units in hidden_units:\n",
        "        layers_list.append(layers.Dense(units, activation=activation, kernel_regularizer=kernel_reg))\n",
        "        if dropout_rate and dropout_rate > 0:\n",
        "            layers_list.append(layers.Dropout(dropout_rate))\n",
        "    layers_list.append(layers.Dense(1))\n",
        "    model = keras.Sequential(layers_list)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate), loss='mse')\n",
        "    return model\n",
        "\n",
        "results = []\n",
        "\n",
        "all_combos = list(itertools.product(\n",
        "    param_grid['hidden_units_list'],\n",
        "    param_grid['activation'],\n",
        "    param_grid['learning_rate'],\n",
        "    param_grid['batch_size'],\n",
        "    param_grid['l2_value'],\n",
        "    param_grid['dropout_rate'],\n",
        "))\n",
        "\n",
        "print(f'Всего комбинаций: {len(all_combos)}')\n",
        "\n",
        "for (hidden_units, activation, lr, batch, l2_val, dr) in all_combos:\n",
        "    model = build_mlp(\n",
        "        input_dim=input_dim,\n",
        "        hidden_units=hidden_units,\n",
        "        activation=activation,\n",
        "        l2_value=l2_val,\n",
        "        dropout_rate=dr,\n",
        "        learning_rate=lr,\n",
        "    )\n",
        "    es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "    model.fit(\n",
        "        X_tr_std, y_tr.values,\n",
        "        validation_data=(X_va_std, y_va.values),\n",
        "        epochs=200, batch_size=batch, verbose=0, callbacks=[es]\n",
        "    )\n",
        "\n",
        "    # Оценка на val\n",
        "    y_tr_pred = model.predict(X_tr_std, verbose=0).ravel()\n",
        "    y_va_pred = model.predict(X_va_std, verbose=0).ravel()\n",
        "\n",
        "    rmse_tr = float(np.sqrt(mean_squared_error(y_tr, y_tr_pred)))\n",
        "    r2_tr = float(r2_score(y_tr, y_tr_pred))\n",
        "    rmse_va = float(np.sqrt(mean_squared_error(y_va, y_va_pred)))\n",
        "    r2_va = float(r2_score(y_va, y_va_pred))\n",
        "\n",
        "    results.append({\n",
        "        'hidden_units': hidden_units,\n",
        "        'activation': activation,\n",
        "        'learning_rate': lr,\n",
        "        'batch_size': batch,\n",
        "        'l2_value': l2_val,\n",
        "        'dropout_rate': dr,\n",
        "        'rmse_train': rmse_tr,\n",
        "        'r2_train': r2_tr,\n",
        "        'rmse_val': rmse_va,\n",
        "        'r2_val': r2_va,\n",
        "    })\n",
        "\n",
        "# Таблица результатов\n",
        "grid_results_df = pd.DataFrame(results)\n",
        "# Лучшее по RMSE на валидации, при равенстве — по R^2\n",
        "grid_results_df.sort_values(['rmse_val', 'r2_val'], ascending=[True, False], inplace=True)\n",
        "print('Топ-10 конфигураций по валид. RMSE:')\n",
        "print(grid_results_df.head(10).to_string(index=False))\n",
        "\n",
        "best_row = grid_results_df.iloc[0]\n",
        "best_params = {\n",
        "    'hidden_units': tuple(best_row['hidden_units']),\n",
        "    'activation': str(best_row['activation']),\n",
        "    'learning_rate': float(best_row['learning_rate']),\n",
        "    'batch_size': int(best_row['batch_size']),\n",
        "    'l2_value': float(best_row['l2_value']),\n",
        "    'dropout_rate': float(best_row['dropout_rate']),\n",
        "}\n",
        "\n",
        "print('\\nЛучшие гиперпараметры:')\n",
        "for k, v in best_params.items():\n",
        "    print(f'{k}: {v}')\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Обучение лучшей конфигурации на train+val и оценка на test\n",
        "keras = tf.keras\n",
        "\n",
        "assert 'grid_results_df' in globals(), 'Сначала выполните ячейку с grid search.'\n",
        "assert 'X_train' in globals() and 'X_val' in globals() and 'X_test' in globals(), 'Сначала выполните train/val/test split.'\n",
        "\n",
        "TARGET = 'Y house price of unit area'\n",
        "\n",
        "# Лучшие параметры из предыдущей ячейки\n",
        "best_row = grid_results_df.iloc[0]\n",
        "best_params = {\n",
        "    'hidden_units': tuple(best_row['hidden_units']),\n",
        "    'activation': str(best_row['activation']),\n",
        "    'learning_rate': float(best_row['learning_rate']),\n",
        "    'batch_size': int(best_row['batch_size']),\n",
        "    'l2_value': float(best_row['l2_value']),\n",
        "    'dropout_rate': float(best_row['dropout_rate']),\n",
        "}\n",
        "\n",
        "# Данные: df_original\n",
        "df = df_original.copy() if 'df_original' in globals() else dataset.copy()\n",
        "X_all = df.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
        "y_all = df[TARGET]\n",
        "\n",
        "# train+val и test\n",
        "trainval_idx = pd.Index(X_train.index).union(X_val.index)\n",
        "X_trval = X_all.loc[trainval_idx]\n",
        "y_trval = y_all.loc[trainval_idx]\n",
        "X_te = X_all.loc[X_test.index]\n",
        "y_te = y_all.loc[X_test.index]\n",
        "\n",
        "# Imputer+Scaler по train+val\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "X_trval_imp = imputer.fit_transform(X_trval)\n",
        "X_te_imp = imputer.transform(X_te)\n",
        "X_trval_std = scaler.fit_transform(X_trval_imp)\n",
        "X_te_std = scaler.transform(X_te_imp)\n",
        "\n",
        "# Построение модели по лучшим параметрам\n",
        "from tensorflow.keras import regularizers\n",
        "kernel_reg = regularizers.l2(best_params['l2_value']) if best_params['l2_value'] > 0 else None\n",
        "\n",
        "layers_list = [layers.Input(shape=(X_trval_std.shape[1],))]\n",
        "for units in best_params['hidden_units']:\n",
        "    layers_list.append(layers.Dense(units, activation=best_params['activation'], kernel_regularizer=kernel_reg))\n",
        "    if best_params['dropout_rate'] > 0:\n",
        "        layers_list.append(layers.Dropout(best_params['dropout_rate']))\n",
        "layers_list.append(layers.Dense(1))\n",
        "\n",
        "model = keras.Sequential(layers_list)\n",
        "model.compile(optimizer=keras.optimizers.Adam(best_params['learning_rate']), loss='mse')\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_trval_std, y_trval.values,\n",
        "    epochs=300, batch_size=best_params['batch_size'], verbose=0,\n",
        "    validation_split=0.1, callbacks=[es]\n",
        ")\n",
        "\n",
        "# Оценка на тесте\n",
        "y_test_pred = model.predict(X_te_std, verbose=0).ravel()\n",
        "rmse_test_tuned = float(np.sqrt(mean_squared_error(y_te, y_test_pred)))\n",
        "r2_test_tuned = float(r2_score(y_te, y_test_pred))\n",
        "\n",
        "print('Лучшие гиперпараметры (из grid search):')\n",
        "for k, v in best_params.items():\n",
        "    print(f'{k}: {v}')\n",
        "\n",
        "print('\\nTest RMSE (tuned):', f'{rmse_test_tuned:.6f}')\n",
        "print('Test R^2 (tuned):', f'{r2_test_tuned:.6f}')\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# Сравнение метрик до и после тюнинга на test\n",
        "# Требуется, чтобы до тюнинга уже была ячейка с оценкой Test RMSE/R^2 (нетюнингованной MLP)\n",
        "\n",
        "assert 'rmse_test' in globals() or 'rmse_test_tuned' in globals(), 'Сначала выполните предыдущие ячейки.'\n",
        "\n",
        "# Если есть старые метрики (из ячейки оценки до тюнинга), напечатаем обе\n",
        "rows = []\n",
        "if 'rmse_test' in globals() and 'r2_test' in globals():\n",
        "    rows.append({'model': 'MLP (до тюнинга)', 'test_rmse': float(rmse_test), 'test_r2': float(r2_test)})\n",
        "if 'rmse_test_tuned' in globals() and 'r2_test_tuned' in globals():\n",
        "    rows.append({'model': 'MLP (после тюнинга)', 'test_rmse': float(rmse_test_tuned), 'test_r2': float(r2_test_tuned)})\n",
        "\n",
        "cmp_df = pd.DataFrame(rows)\n",
        "print(cmp_df.to_string(index=False))\n",
        "\n",
        "if len(rows) == 2:\n",
        "    delta_rmse = rows[1]['test_rmse'] - rows[0]['test_rmse']\n",
        "    delta_r2 = rows[1]['test_r2'] - rows[0]['test_r2']\n",
        "    print(f\"\\nΔRMSE (tuned - base): {delta_rmse:+.6f}\")\n",
        "    print(f\"ΔR^2  (tuned - base): {delta_r2:+.6f}\")\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# 6.2 Algorithm Comparison: валидация (по результатам grid search)\n",
        "# Требуется выполненная ячейка grid search -> переменная grid_results_df\n",
        "assert 'grid_results_df' in globals(), 'Сначала выполните ячейку с grid search.'\n",
        "\n",
        "# Сформируем «имена» как 1..N для наглядности и вытащим списки RMSE/R^2\n",
        "names_val = list(range(1, len(grid_results_df) + 1))\n",
        "rmse_val_list = grid_results_df['rmse_val'].tolist()\n",
        "r2_val_list = grid_results_df['r2_val'].tolist()\n",
        "\n",
        "print('Names:', names_val[:10] if len(names_val) > 10 else names_val)\n",
        "print('Rmse:', rmse_val_list[:10] if len(rmse_val_list) > 10 else rmse_val_list)\n",
        "print('R2:', r2_val_list[:10] if len(r2_val_list) > 10 else r2_val_list)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.scatter(names_val, rmse_val_list, c='tab:blue', label='RMSE (val)')\n",
        "plt.scatter(names_val, r2_val_list, c='tab:orange', label='R² (val)')\n",
        "plt.title('Algorithm Comparison (Validation)')\n",
        "plt.xlabel('Config index')\n",
        "plt.ylabel('Metric value')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### BEGIN YOUR CODE\n",
        "# 7.1 Test Algorithm Comparison: сравнение топ-K конфигураций на тесте\n",
        "# Возьмём первые K лучших по валидации и оценим их на тесте\n",
        "\n",
        "assert 'grid_results_df' in globals(), 'Нужны результаты grid search.'\n",
        "assert 'X_train' in globals() and 'X_val' in globals() and 'X_test' in globals(), 'Нужен train/val/test split.'\n",
        "\n",
        "K = 6\n",
        "sub_df = grid_results_df.head(K).copy()\n",
        "\n",
        "# Подготовим данные: df_original, train+val для обучения, test для оценки\n",
        "TARGET = 'Y house price of unit area'\n",
        "df = df_original.copy() if 'df_original' in globals() else dataset.copy()\n",
        "X_all = df.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
        "y_all = df[TARGET]\n",
        "\n",
        "trainval_idx = pd.Index(X_train.index).union(X_val.index)\n",
        "X_trval = X_all.loc[trainval_idx]\n",
        "y_trval = y_all.loc[trainval_idx]\n",
        "X_te = X_all.loc[X_test.index]\n",
        "y_te = y_all.loc[X_test.index]\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Преобразования по train+val\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = StandardScaler()\n",
        "X_trval_imp = imputer.fit_transform(X_trval)\n",
        "X_te_imp = imputer.transform(X_te)\n",
        "X_trval_std = scaler.fit_transform(X_trval_imp)\n",
        "X_te_std = scaler.transform(X_te_imp)\n",
        "\n",
        "rmse_test_list = []\n",
        "r2_test_list = []\n",
        "config_ids = list(range(1, len(sub_df) + 1))\n",
        "\n",
        "for _, row in sub_df.iterrows():\n",
        "    hidden_units = tuple(row['hidden_units'])\n",
        "    activation = str(row['activation'])\n",
        "    lr = float(row['learning_rate'])\n",
        "    batch = int(row['batch_size'])\n",
        "    l2_val = float(row['l2_value'])\n",
        "    dr = float(row['dropout_rate'])\n",
        "\n",
        "    layers_list = [layers.Input(shape=(X_trval_std.shape[1],))]\n",
        "    kernel_reg = regularizers.l2(l2_val) if l2_val > 0 else None\n",
        "    for units in hidden_units:\n",
        "        layers_list.append(layers.Dense(units, activation=activation, kernel_regularizer=kernel_reg))\n",
        "        if dr > 0:\n",
        "            layers_list.append(layers.Dropout(dr))\n",
        "    layers_list.append(layers.Dense(1))\n",
        "\n",
        "    model = tf.keras.Sequential(layers_list)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='mse')\n",
        "\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "    model.fit(\n",
        "        X_trval_std, y_trval.values,\n",
        "        epochs=250, batch_size=batch, verbose=0,\n",
        "        validation_split=0.1, callbacks=[es]\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_te_std, verbose=0).ravel()\n",
        "    rmse_test_list.append(float(np.sqrt(mean_squared_error(y_te, y_pred))))\n",
        "    r2_test_list.append(float(r2_score(y_te, y_pred)))\n",
        "\n",
        "print('Names:', config_ids)\n",
        "print('Rmse:', rmse_test_list)\n",
        "print('R2:', r2_test_list)\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.scatter(config_ids, rmse_test_list, c='tab:blue', label='RMSE (test)')\n",
        "plt.scatter(config_ids, r2_test_list, c='tab:orange', label='R² (test)')\n",
        "plt.title('Test Algorithm Comparison (top-K from validation)')\n",
        "plt.xlabel('Config index (top-K by val)')\n",
        "plt.ylabel('Metric value')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# ### END YOUR CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Выводы\n",
        "- Лучший тип модели для табличных данных: MLP (полносвязная сеть); SimpleRNN уступает по RMSE и R² на всех наборах.\n",
        "- Лучший набор данных: `df_original` (без инженерии/стандартизации) на вал. сплите; после гипертюнинга на тесте также лучший.\n",
        "- Лучшая конфигурация (Grid): hidden_units=(64,32,16), activation=relu, lr=3e-4, batch=16, L2=1e-4, dropout=0.0, EarlyStopping(patience=20).\n",
        "- Качество (test):\n",
        "  - До тюнинга: RMSE 6.976, R² 0.7099\n",
        "  - После тюнинга: RMSE 6.936, R² 0.7133\n",
        "  - Улучшение: ΔRMSE −0.0409 (≈ −0.6%), ΔR² +0.0034 (≈ +0.5%).\n",
        "- Предобработка и агрессивная инженерия признаков в этой задаче не дали выигрыша; простая MLP с тонкой настройкой гиперпараметров оказалась оптимальной.\n",
        "- Потенциал дальнейшего улучшения (при необходимости): расширение сетки (например, (128,64,32), (64,48,32,16), lr ∈ {1e-4, 2e-4, 5e-4}, L2 ∈ {5e-5, 2e-4}, небольшие ансамбли), кросс-валидация вместо одного вал. сплита."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
